---
title: "Cleaning strings with regular expressions using base R or stringr"
author: Erika Duan
date: "`r Sys.Date()`"
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, results="hide", message=FALSE, warning=FALSE)
```

```{r}  
# Load required R packages -----------------------------------------------------
if (!require("pacman")) install.packages("pacman")
pacman::p_load(here,  
               dplyr,  
               stringr,
               ggplot2,
               microbenchmark) 
```


# Introduction   

When you have short free text fields to analyse, it can be useful to perform data cleaning using regular expressions instead of advanced natural language processing (NLP) models first.   

Regular expressions, or regex, is a separate syntax for identifying any pattern inside a string. In R, regex can be directly enclosed inside quotes like character strings or explicitly referenced inside `regex()`. The former approach is more convenient but the latter approach can help increase code readability.    

```{r}
# Call regular expressions in R directly using "" ------------------------------
many_apples <- c("Apple", "apple", "APPLE", "apples")

str_extract(many_apples, 
            "apples?")  
#> [1] NA       "apple"  NA       "apples"

# Call regular expressions in R using regex() ----------------------------------
# regex() provides additional arguments with ignore_case = FALSE as default
str_extract(many_apples, 
            regex("apples?", ignore_case = TRUE))  
#> [1] "Apple"  "apple"  "APPLE"  "apples"

# regex() allows comments to improve code readability  
str_extract(many_apples, 
            regex("
                  apple  # contains the word apple
                  s?  # contains zero or one of the letter s
                  ", 
                  comments = T))
#> [1] NA       "apple"  NA       "apples"    
```


# Using regex with `stringr`   

The `stringr` package is built on top of the fast `stringi` R package and provides more consistent function names. For example, `str_extract()` extracts the matching pattern whereas `str_detect()` returns the boolean variable `TRUE` if the regex matches.  

```{r}
# Compare different stringr str_*() functions ----------------------------------
many_apples <- c("Apple", "apple", "APPLE", "apples")

str_extract(many_apples, 
            "a|e")  
#> [1] "e" "a" NA  "a"

str_detect(many_apples, 
           "a|e")   
#> [1]  TRUE  TRUE FALSE  TRUE

str_replace(many_apples, 
           "a|e", # detect a or e
           "o") # replace with o
#> [1] "Applo"  "opple"  "APPLE"  "opples"  

str_replace_all(many_apples, 
                "a|e", 
                "o") 
#> [1] "Applo"  "opplo"  "APPLE"  "opplos"
```

## Matching characters   

In regex, the meaning of a pattern changes depending on whether it is preceded by `\`. For example, `s` matches the letter `"s"` but `\s` is used to match any type of white space.     

In R, some regex syntax differences exist:    

+ A second backslash `\` is required to escape special character behaviour i.e. `\\s` instead of `\s` matches any type of white space.   
+ Punctuation marks must be referenced by a preceding `\`. For example, only the regex `\?` matches the pattern `?`.   
+ A consequence of these two behaviours is that the punctuation mark `\` is represented by the regex `\\\\` in R.   

```{r}
# Extract white space(s) in R --------------------------------------------------  
words_and_spaces <- c("a cat",
                      "acat",
                      "a   cat",
                      "a\ncat",
                      "a\\ncat")

# "a\\s+cat" calls variations of "a...cat" separated by one or more white spaces 
# "a\ncat" is a match because "\n" refers to a new line in R

str_extract(words_and_spaces, "a\\s+cat")  
#> [1] "a cat"   NA        "a   cat" "a\ncat"  NA      

# "\\S+" refers to everything that is not white space   

str_extract(words_and_spaces, "\\S+")  
#> [1] "a"       "acat"    "a"       "a"       "a\\ncat"

str_extract_all(words_and_spaces, "\\S+")
#> [[1]]
#> [1] "a"   "cat"

#> [[2]]
#> [1] "acat"

#> [[3]]
#> [1] "a"   "cat"

#> [[4]]
#> [1] "a"   "cat"

#> [[5]]
#> [1] "a\\ncat"

# str_extract_all() returns a list of one or more character vectors. Each 
# list element contains all matches identified for each pattern of interest. 
```

In regex, the special characters like `\s` versus `\S`, `\d` versus `\D` and `\w` versus `\W` allow the extraction of opposite pattern types. For example, `\w` refers to any word character (including digits) whilst `\W` and `[^\w]` both refer to anything that is not a word character.     

```{r}
# Extract opposite pattern types using regex ----------------------------------- 
character_jumble <- c("meow",
                      "me0w!",
                      "mew mew",
                      "me\new")

str_extract(character_jumble, "\\w+")
#> [1] "meow" "me0w" "mew"  "me"  

str_extract(character_jumble, "\\W+")
#> [1] NA   "!"  " "  "\n"

str_extract(character_jumble, "[^\\w]")
#> [1] NA   "!"  " "  "\n"
```

## Character anchors   

Character anchors are useful for capturing patterns at the start or end of a string. Use `^` and `$` to denote the start and end of the string respectively. The presence or absence of character anchors can produce very different outputs.        

```{r}
# Character anchors can alter the regex pattern --------------------------------    
more_words_and_spaces <- c("a cat",
                           " a cat",
                           "acat",
                           "a   cat",
                           "a\ncat",
                           "a\\ncat")

# "\\S+" refers to 1+ non-white spaces 

# Extract the first 1+ non-white spaces present in a pattern
str_extract(more_words_and_spaces, "\\S+")  
#> [1] "a"       "a"       "acat"    "a"       "a"       "a\\ncat" 

# Only extract 1+ non-white spaces that exist at the start of a pattern
str_extract(more_words_and_spaces, "^\\S+")  
#> [1] "a"       NA        "acat"    "a"       "a"       "a\\ncat"

# Only extract 1+ non-white spaces that exist at the end of a pattern
str_extract(more_words_and_spaces, "\\S+$") 
#> [1] "cat"     "cat"     "acat"    "cat"     "cat"     "a\\ncat"      
```

## Character classes and groupings   

Character classes are enclosed by `[]` and represent a single character of interest. Groupings are enclosed by `()` and used to denote 2+ characters of interest.  

Special characters can be used inside character classes and groupings:        

+ The operation `or` is represented by `|` i.e `[a|c]`       
+ The operation `range` is represented by `-` i.e. `[a-z]`      
+ The operation `excludes` is represented by `^` i.e. `[^a-c]`   

```{r}
# Extract patterns using character classes -------------------------------------    
strange_fruits <- c("apple1",
                    "bapple2",
                    "capple3",
                    "dapple4",
                    "epple5",
                    "aggle0")

str_extract(strange_fruits, "[a-d]")
#> [1] "a" "b" "c" "d" NA  "a"  

str_extract(strange_fruits, "[a-d][^p]")
#> [1] NA   "ba" "ca" "da" NA   "ag"   

# The regex [a-d][^p] refers to one character that is a, b, c or d followed by 
# one character that is not p.  

str_extract(strange_fruits, "[0|4-9]")
#> [1] NA  NA  NA  "4" "5" "0"   

# The regex [0|4-9] refers to one number that is 0 or 4 to 9    
```

```{r}
# Extract patterns using groupings ---------------------------------------------     
stranger_fruits <- c("applepp1",
                    "bapplegg2",
                    "cagglegg3",
                    "dapple4",
                    "epple5",
                    "apgle0")  

str_extract(stranger_fruits, "a(pp|gg)le")
#> [1] "apple" "apple" "aggle" "apple" NA      NA    

# Groups can be referenced by their order of appearance i.e. \\1 is first group   

str_extract(stranger_fruits, "a(pp|gg).+\\1")
#> [1] "applepp" NA        "agglegg" NA        NA        NA      

str_extract(stranger_fruits, "a(p|g)\\1")
#> [1] "app" "app" "agg" "app" NA    NA     

# When OR is used inside a grouping and the group is referenced again, 
# the latter reference is identical to the first. For example, "a(p|g)\\1" 
# extracts "app" and "agg" but not "apg" or "agp". 
```

## Greedy versus lazy matches   

In R, regex parsing is non-greedy by default (the search stops at the shortest first result). Using a non-greedy match allows you to only extract the first characters before a white space or punctuation mark, which is useful for trimming strings or extracting file and object names. 

This also means that we need to explicitly use quantifiers like `*` and `+` to greedily extract subsequent characters of interest.      

```{r, echo=FALSE, results='markup' , fig.align='center', out.width='80%', fig.cap='Taken from the RStudio stringr cheatsheet'} 
knitr::include_graphics("../../figures/dc-cleaning_strings-greedy_matches.jpg")      
```   

```{r}
# Extract patterns using quantifiers -------------------------------------------   
messy_dates <- c("Thursday 24th May",
                 "Thursday  24th May  ",
                 " May",
                 "May    ")

str_extract(messy_dates, "^\\w")      
#> [1] "T" "T" NA  "M"   

# Greedily extract the first word in the string    
str_extract(messy_dates, "^\\w+")   
#> [1] "Thursday" "Thursday" NA      "May"   

# The quantifiers + and {1,} are equivalent
str_extract(messy_dates, "^\\w{1,}")     
#> [1] "Thursday" "Thursday" NA      "May"    

# Differences between str_* and str_*_all --------------------------------------
# str_replace() replaces the first match only i.e. non-greedy replacement
str_replace(messy_dates, "\\s" , "-") 
#> [1] "Thursday-24th May"    "Thursday- 24th May  " "-May"                 "May-   "       

# str_replace_all() replaces every match 
str_replace_all(messy_dates, "\\s" , "-") 
#> [1] "Thursday-24th-May"    "Thursday--24th-May--" "-May"                 "May----"  

str_replace_all(messy_dates, "\\s{1,2}" , "-") 
#> [1] "Thursday-24th-May"  "Thursday-24th-May-" "-May"                "May--"         
```

## Look arounds    

Look around operations are useful when you are unsure of the pattern of interest but you know what appears before or after it. 

```{r, echo=FALSE, results='markup', fig.align='center', out.width='80%', fig.cap='Taken from the RStudio stringr cheatsheet'} 
knitr::include_graphics("../../figures/dc-cleaning_strings-look_arounds.jpg")  
```

```{r}
# Extract patterns using look arounds ------------------------------------------  
recipes <- c("crossiant recipes",
             "apple pie recipe",
             "chocolate cake  recipe", # Extra white space
             "cookie receipe",  # Typo
             "secret KFC-recipe", 
             "very secret  McDonalds soft-serve recipe") # Extra white space  

# Use positive look-aheads (?=...) to extract the word before the pattern ------
# Extract all non white space characters before " recipes"
str_extract(recipes, "\\S+(?=\\srecipes?)")   
#> [1] "crossiant"  "pie"        NA           NA           NA           "soft-serve"   

# Extract all non white space characters before "recipes" preceded by zero or 
# more white spaces. 
str_extract(recipes, "\\S+(?=\\s*recipes?)")   
#> [1] "crossiant"  "pie"        "cake"       NA           "KFC-"       "soft-serve"

# Use positive look-behinds (?<=) to extract the word after the pattern --------   
str_extract(recipes, "(?<=secret\\s{1,2})\\S+")   
# [1] NA           NA           NA           NA           "KFC-recipe" "McDonalds" 

str_extract(recipes, "(?<=secret\\s{1,2}).+")  
#> [1] NA          NA           NA           NA                            
#> [5] "KFC-recipe"                   " McDonalds soft-serve recipe"  
```

**Note:** Positive look-behinds require defined boundaries i.e. use`{1,100}` instead of the operation `+`.    


# Using base R versus `stringr` functions    

The advantages of using `stringr` are its consistent function names and reasonably fast execution speed. To minimise R package dependencies, however, base R can also be used for the same operations. 

The key difference between base R and `stringr` functions is the order that the string and pattern are specified. In base R, the pattern is specified first, which is not a pipe friendly argument order.          

```{r} 
# Extract the position of the matching string using grep() or str_which() ------ 
desserts <- c("chocolate",
              "chocolate cake",
              "chocolate tart",
              "chocolate icecream",
              "chocolate cookies",
              "dark chocolate fudge", 
              "fruit",
              "fruit tart",
              "fruit sorbet")

grep(".*\\bchocolate\\b.*", desserts, value = F) # default is value = FALSE
#> [1] 1 2 3 4 5 6  

str_which(desserts, ".*\\bchocolate\\b.*")  
#> [1] 1 2 3 4 5 6  
```

```{r}
# Extract the matching original string using grep() or str_subset() ------------
grep(".*\\bchocolate\\b.*", desserts, value = T) 
#> [1] "chocolate"            "chocolate cake"       "chocolate tart"       "chocolate icecream"  
#> [5] "chocolate cookies"    "dark chocolate fudge"  

str_subset(desserts, ".*\\bchocolate\\b.*") 
#> [1] "chocolate"            "chocolate cake"       "chocolate tart"       "chocolate icecream"  
#> [5] "chocolate cookies"    "dark chocolate fudge"  

# str_subset() is a wrapper around x[str_detect(x, pattern)]  
```

```{r}
# Extract a boolean variable using grepl() or str_detect() ---------------------  
grepl(".*\\bchocolate\\b.*", desserts) 
#> [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  

str_detect(desserts, ".*\\bchocolate\\b.*")  
#> [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  
```

```{r}
# Replace a pattern using gsub() or str_replace() ------------------------------    
more_desserts <- c("chocolate chocolate",
                   "chocolate cake",
                   "chocolate tart",
                   "chocolate icecream",
                   "chocolate cookies",
                   "dark chocolate fudge", 
                   "fruit",
                   "fruit tart",
                   "fruit sorbet")

gsub("chocolate", "vanilla", more_desserts) 
#> [1] "vanilla vanilla"    "vanilla cake"       "vanilla tart"       "vanilla icecream"   
#> [5] "vanilla cookies"    "dark vanilla fudge" "fruit"              "fruit tart"         "fruit sorbet"  

str_replace(more_desserts, "chocolate", "vanilla")
#> [1] "vanilla chocolate"  "vanilla cake"       "vanilla tart"       "vanilla icecream"   
#> [5] "vanilla cookies"    "dark vanilla fudge" "fruit"              "fruit tart"         "fruit sorbet"  

str_replace_all(more_desserts, "chocolate", "vanilla") 
#> [1] "vanilla vanilla"    "vanilla cake"       "vanilla tart"       "vanilla icecream"   
   
# gsub() behaves similarly to str_replace_all() not str_replace()
```

We can benchmark equivalent base R versus `stringr` operations to compare their execution speeds. Most `stringr` functions are slightly faster than their base R equivalents.    

```{r, echo=FALSE, message=FALSE, fig.align="center", out.width='70%'}
baser_vs_stringr <- microbenchmark(
  str_replace_all = str_replace_all(desserts, "chocolate", "vanilla"),
  gsub = gsub("chocolate", "vanilla", desserts),
  str_detect = str_detect(desserts, ".*\\bchocolate\\b.*"),  
  grepl = grepl(".*\\bchocolate\\b.*", desserts),
  str_subset = str_subset(desserts, ".*\\bchocolate\\b.*"),
  grep_value_true = grep(".*\\bchocolate\\b.*", desserts, value = TRUE),
  str_which = str_which(desserts, ".*\\bchocolate\\b.*"),
  grep_value_false = grep(".*\\bchocolate\\b.*", desserts, value = FALSE),
  times = 1000
)

autoplot(baser_vs_stringr)
```


# Cleaning free text fields using `stringr`       

Imagine that my favourite chocolate company, [Haighs Chocolates](https://www.haighschocolates.com.au), wants to understand what food critics versus past consumers think about their newest product. They send out a bag of free samples with a link to an online survey that asks individuals to rate their chocolates (on a scale of 1 to 10) and provide additional comments.    

We can source the R script [./dc-cleaning_strings-dataset_generation_script.R](./dc-cleaning_strings-dataset_generation_script.R) to generate mock survey results.   

```{r}
# Source R script to generate mock survey results ------------------------------
# Explicitly states that outputs are generated in the global R environment   
source("dc-cleaning_strings-dataset_generation_script.R",
       local = knitr::knit_global())
```

```{r, results='markup'}
# Preview mock survey results --------------------------------------------------  
survey %>%
  head()  
```

We can improve the readability of the comment fields by removing all HTML tags. Cleaning the comment fields also enables us to perform more advanced NLP tasks using text analysis packages.  

```{r, results='markup'}
# Remove HTML tags using regex -------------------------------------------------
remove_html_tags <- regex("
                          <  # Starts with <
                          [^>]+  # Contains one or more of all characters except > 
                          >  # Ends with >
                          ", 
                          comments = T)

remove_more_html <- regex("
                          \\& # Starts with &
                          \\w+ # Contains one or more word characters
                          \\; # Ends with ;
                          ", 
                          comments = T) 

remove_newlines <- regex("\n")

survey <- survey %>%
  mutate(comment_field = str_replace_all(comment_field, remove_html_tags, ""),
         comment_field = str_replace_all(comment_field, remove_more_html, ""),
         comment_field = str_replace_all(comment_field, remove_newlines, ""))

# Examine comment fields -------------------------------------------------------  
survey %>%
  select(comment_field) %>%
  head() 
```

From the comment fields, we can see that information about the cocoa bean grade is highly structured. Using regex is sufficient for extracting this information. 

```{r, results='markup'}
# Extract cocoa bean grade using regex -----------------------------------------
extract_cocoa_grade <- regex("
                             (?<= # Extract the pattern preceding...
                             [G|g]rade # Grade or grade...
                             \\W{0,2}) # followed by 0 to 2 non-characters 
                             [A-E|a-e] # The pattern must be A, B, C, D or E
                             ", 
                             comments = T)  

tidy_survey <- survey %>%
  mutate(cocoa_grade = str_extract(comment_field, extract_cocoa_grade),
         cocoa_grade = str_to_upper(cocoa_grade)) 

# Examine tidy_survey ----------------------------------------------------------  
tidy_survey %>%
  head()  
```

This then allows us to perform simple analysis on the mention of cocoa bean grade by survey respondee type. 

```{r, results='markup'}
# Summarise relationship between cocoa bean grade and respondee type -----------
extract_respondee_type <- regex("
                                \\w+ # One or more word characters
                                (?=_) # which occur before _
                                ", 
                                comments = T)

tidy_survey %>% 
  mutate(respondee_type = str_extract(respondee, extract_respondee_type)) %>%
  count(respondee_type, cocoa_grade) 
```


# Other resources   

+ Tutorial examples are based on the excellent [regex vignette](https://cran.r-project.org/web/packages/stringr/vignettes/regular-expressions.html) from `stringr`.  
+ [Strings chapter](https://r4ds.had.co.nz/strings.html) from R4DS by Garrett Grolemund and Hadley Wickham.         
+ The RStudio [`stringr` cheatsheet](https://github.com/rstudio/cheatsheets/blob/master/strings.pdf).    
+ Regex testing [site](https://regex101.com/)       
  